# BAMDP: Bayes-adaptive Markov Decision Process
duff_2002

Duff~\cite{Duff2002} in 2002 coins the term BAMDP, which refers to
a Bayesian formulation of Markov decision processes with uncertainty in their state-transition probabilities.
Note that reinforcement learning is typically applied to MDP having extremely large number of states and
possibly unknown dynamics.

In BAMDP, we regard `state` as an ordered pair, `hyperstate`, $(s,x)$, where
$s$ is the physical state, while
$x$ is the information status that summarizes the history related to the transition dynamics of~$s$.

To model the uncertainty, we may use the conjugate family distribution for the sake of convenient computation.
For example, Beta distribution, which is the appropriate conjugate family of Bernoulli distribtion.
If our uncertainty is modeled in Beta distribution , then the posterios is also Besta distribution.
The conjugate family of multinomial distribution is Dirichlet distribution.

At a suitable level of abstraction, BAMDP can be cast as POMDP.
Therefore, POMDP approaches may be generalized and applied to BAMDP.
