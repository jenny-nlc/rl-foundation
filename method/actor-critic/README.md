# actor-critic

## variant
### openai
* [ACKTR: Actor Critic using Kronecker-Factored Trust Region, 2017)](acktr_wu_2017.md)

### deepmind
* [Reactor: A Sample-Efficient Actor-Critic Architecture, 2018)](reactor_gruslys_2018.md)
* [ACER: Sample efficient actor-critic with experience replay](acer_wang_2017.md)
* [PGQL: Combining policy gradient and q-learning, 2017](pgql_donoghue_2017.md)
* [A3C: Asynchronous(Synchronous) advantage actor-critic, 2016)](a3c_mnih_2016.md)

### other
* [Dual-AC: Boosting the Actor with Dual Critic, 2017](dualac_dai_2017.md)
* [PCL: Bridging the Gap Between Value and Policy Based Reinforcement Learning, 2017](pcl_nachum_2017.md)
* [Soft Actor-Critic: Off-Policy Maximum Entropy Deep RL with a Stochastic Actor, 2017](sac_haarnoja_2017.md)

### legend
* [Off-PAC: off-Policy Actor-Critic, 2012](offpac_degris_2012.md)
* [Natural Actor-Critic, 2008)](nac_peters_2008.md)
* [Actor-Critic Algorithms, 1999](ac_konda_1999.md)

## actor-critic based
* 2016: Progressive Nets
* 2015: Deep DPG

## foundation
### book
* RL Intro (Sutton, 2018): 13.5, 15.7

### talk, lecture, tutorial
* http://mi.eng.cam.ac.uk/~mg436/LectureSlides/MLSALT7/L5.pdf
* http://www.inf.ed.ac.uk/teaching/courses/rl/slides15/rl12.pdf
* http://www.rage.net/~greg/2016-07-05-ActorCritic-with-OpenAI-Gym.html
* [Survey: 2012: Grondman: A Survey of Actor-Critic Reinforcement Learning: Standard and Natural Policy Gradients](http://ieeexplore.ieee.org/abstract/document/6392457/), see [survey](https://github.com/tttor/rl-foundation/tree/master/survey)
