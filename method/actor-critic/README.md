# actor-critic

## variant
* [ACKTR: Actor Critic using Kronecker-Factored Trust Region (Wu,2017)](https://arxiv.org/abs/1708.05144)
* [Reactor: A Sample-Efficient Actor-Critic Architecture (Gruslys, 2017)](https://arxiv.org/abs/1704.04651)
* [A3C: Asynchronous(Synchronous) advantage actor-critic (Mnih, 2016)](https://arxiv.org/pdf/1602.01783.pdf)
  * https://github.com/MG2033/A2C
  * https://github.com/openai/baselines/tree/master/baselines/a2c
  * https://github.com/chainer/chainerrl/blob/master/examples/gym/train_a3c_gym.py
  * https://github.com/NVlabs/GA3C  
  * https://github.com/miyosuda/async_deep_reinforce
  * https://github.com/muupan/async-rl
  * https://github.com/dennybritz/reinforcement-learning/tree/master/PolicyGradient/a3c
  * https://github.com/liampetti/A3C-LSTM
  * https://github.com/ikostrikov/pytorch-a3c
  * https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_bipedalwalker_a3c_continuous_action.py
  * https://github.com/rlcode/reinforcement-learning/blob/master/2-cartpole/5-a3c/cartpole_a3c.py
  * [Arthur Juliani @medium.com](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-8-asynchronous-actor-critic-agents-a3c-c88f72a5e9f2)
  * https://jaromiru.com/2017/02/16/lets-make-an-a3c-theory/
  * https://cgnicholls.github.io/reinforcement-learning/2017/03/27/a3c.html
* [Natural Actor-Critic (Peters, 2008)](https://www.sciencedirect.com/science/article/pii/S0925231208000532)

## actor-critic based
* 2016: Progressive Nets
* 2015: Deep DPG

## foundation
### book
* [Survey: 2012: Grondman: A Survey of Actor-Critic Reinforcement Learning: Standard and Natural Policy Gradients](http://ieeexplore.ieee.org/abstract/document/6392457/), see [survey](https://github.com/tttor/rl-foundation/tree/master/survey)

### talk, lecture, tutorial
* http://mi.eng.cam.ac.uk/~mg436/LectureSlides/MLSALT7/L5.pdf
* http://www.inf.ed.ac.uk/teaching/courses/rl/slides15/rl12.pdf

