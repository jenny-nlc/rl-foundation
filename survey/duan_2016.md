# Benchmarking Deep Reinforcement Learning for Continuous Control

## Task
* Basic (5):
  * Cart-Pole Balancing (Stephenson, 1908; Donaldson, 1960; Widrow, 1964; Michie & Chambers, 1968), 
  * Cart-Pole Swing Up (Kimura & Kobayashi, 1999; Doya, 2000), 
  * Mountain Car (Moore, 1990), 
  * Acrobot Swing Up (DeJong &Spong, 1994; Murray&Hauser, 1991; Doya, 2000), and 
  * Double Inverted Pendulum Balancing (Furuta et al., 1978).
* Locomotion (6):
  * Swimmer (Purcell, 1977; Coulom, 2002; Levine & Koltun, 2013; Schulman et al., 2015a), 
  * Hopper (Murthy & Raibert, 1984; Erez et al., 2011; Levine & Koltun, 2013; Schulman et al., 2015a), 
  * Walker (Raibert&Hodgins, 1991; Erez et al., 2011; Levine & Koltun, 2013; Schulman et al., 2015a), 
  * Half-Cheetah (Wawrzynski, 2007; Heess et al., 2015b), 
  * Ant (Schulman et al., 2015b), Simple Humanoid (Tassa et al., 2012; Schul- man et al., 2015b), and 
  * Full Humanoid (Tassa et al., 2012).
* Partially Observable (on basic tasks: 3 x 5):
  * Limited Sensors
  * Noisy Observations and Delayed Actions
  * System Identification
* Hierarchical
  * Locomotion + Food Collection
  * Locomotion + Maze
  
## Algorithms
* Batch Algorithms
  * REINFORCE (Williams, 1992)
  * Truncated Natural Policy Gradient (TNPG) (Peters et al., 2003; Bagnell & Schneider, 2003; Schulman et al., 2015a)
  * Reward-Weighted Regression (RWR) (Peters & Schaal, 2007; Kober & Peters, 2009)
  * Relative Entropy Policy Search (REPS) (Peters et al., 2010)
  * Trust Region Policy Optimization (TRPO) (Schulman et al., 2015a)
  * Cross Entropy Method (CEM) (Rubinstein, 1999; Szita & Lorincz, 2006)
  * Covariance Matrix Adaption Evolution Strategy (CMA-ES) (Hansen & Ostermeier, 2001)
* Online Algorithms
  * Deep Deterministic Policy Gradient (DDPG) (Lillicrap et al., 2015)
* Recurrent Variants

## Experiment Setup
* Hyperparameter Tuning
  * a grid search of hyperparameters is performed
  * Each choice of hyperparameters is executed under five random seeds.
  * The criterion for the best hyperparameters: `mean(returns) âˆ’ std(returns)`. 
    This metric selects against large fluctuations of performance due to overly large step sizes.
  * try both of the best hyperparameters found in the same category, and 
    report the better performance of the two. 
    This gives us insights into both the maximum possible performance when extensive hyperparameter tuning is performed, 
    and the robustness of the best hyperparameters across different tasks.  
    
    
